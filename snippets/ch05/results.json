{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.64, 0.688, 0.664, 0.6532258064516129, 0.7096774193548387], "precision": [0.7232932400932401, 0.8124210526315789, 0.5896094117647059, 0.7382205949167492, 0.7711741718300582], "recall": [0.64, 0.688, 0.664, 0.6532258064516129, 0.7096774193548387], "f1": [0.6342123758594348, 0.6747795097147384, 0.6069111696928408, 0.6175242791804578, 0.6803055476587236], "time": [29.180806875228882, 24.394548892974854, 29.126128911972046, 29.799914121627808, 28.447691917419434]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f9f783a4cb0>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.64, 0.64, 0.624, 0.7096774193548387, 0.7903225806451613], "precision": [0.6952697435897436, 0.740583850931677, 0.6167829647829648, 0.8054590570719603, 0.7970189120443789], "recall": [0.64, 0.64, 0.624, 0.7096774193548387, 0.7903225806451613], "f1": [0.6254650487605151, 0.6194715047594305, 0.5756171771490921, 0.6948418912402627, 0.7698772771519955], "time": [5.165339946746826, 4.643425226211548, 4.378420114517212, 4.23593282699585, 4.200770139694214]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.808, 0.704, 0.824, 0.782258064516129, 0.8709677419354839], "precision": [0.8105461301983041, 0.8026181818181817, 0.8450465949820789, 0.8274769585253456, 0.8899117907182423], "recall": [0.808, 0.704, 0.824, 0.782258064516129, 0.8709677419354839], "f1": [0.8055579574547317, 0.7051309474838886, 0.8196637388570578, 0.7869854427339695, 0.872338061826038], "time": [26.546792030334473, 26.818949222564697, 27.76717734336853, 27.40860915184021, 27.786177158355713]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.848, 0.8, 0.816, 0.8870967741935484, 0.7903225806451613], "precision": [0.8575312217194568, 0.8084689985834151, 0.8320784313725492, 0.8935856219122348, 0.8140456989247312], "recall": [0.848, 0.8, 0.816, 0.8870967741935484, 0.7903225806451613], "f1": [0.8505164299776696, 0.8010845450461284, 0.8172813852813853, 0.8869419558935687, 0.7928213031518749], "time": [4.824862003326416, 4.421217203140259, 4.443912982940674, 4.380933046340942, 4.456831932067871]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f9f783a4cb0>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.512, 0.56, 0.544, 0.45161290322580644, 0.7338709677419355], "precision": [0.5827254901960784, 0.6312000000000001, 0.658491118077325, 0.4409168081494058, 0.8117511520737326], "recall": [0.512, 0.56, 0.544, 0.45161290322580644, 0.7338709677419355], "f1": [0.44093040717736365, 0.5099526829759388, 0.4981889925930847, 0.3771860413054384, 0.7015024564877937], "time": [4.212728261947632, 4.205379009246826, 4.312207937240601, 4.28949499130249, 4.317269802093506]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f9f783a4cb0>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.328, 0.304, 0.344, 0.31451612903225806, 0.27419354838709675], "precision": [0.6485462300495322, 0.2932010882238632, 0.4537358490566038, 0.24039856848710658, 0.29868537403658], "recall": [0.328, 0.304, 0.344, 0.31451612903225806, 0.27419354838709675], "f1": [0.31714707088632554, 0.1783710144927536, 0.2663116883116883, 0.19349821584307478, 0.17330672031504035], "time": [26.441608905792236, 28.65755867958069, 28.173328161239624, 29.701281785964966, 27.554853916168213]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression (TruncatedSVD)", "accuracy": [0.68, 0.68, 0.728, 0.6693548387096774, 0.6774193548387096], "precision": [0.8316284175642088, 0.7619836060740086, 0.6401778358940831, 0.7495139195757843, 0.7155533208362622], "recall": [0.68, 0.68, 0.728, 0.6693548387096774, 0.6774193548387096], "f1": [0.6748267583205889, 0.6679338566703997, 0.665308971337615, 0.6284240461659817, 0.6557461179750974], "time": [30.016950130462646, 29.053856372833252, 29.176037549972534, 28.29095149040222, 29.13283634185791]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f8a8bcb6830>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 LogisticRegression(C=1.0, class_weight=None, dual=False,\n                                    fit_intercept=True, intercept_scaling=1,\n                                    l1_ratio=None, max_iter=100,\n                                    multi_class='warn', n_jobs=None,\n                                    penalty='l2', random_state=None,\n                                    solver='warn', tol=0.0001, verbose=0,\n                                    warm_start=False))],\n         verbose=False)", "name": "LogisticRegression", "accuracy": [0.616, 0.792, 0.664, 0.6129032258064516, 0.6612903225806451], "precision": [0.595366818873668, 0.8373904761904762, 0.6652939682539682, 0.7139336917562723, 0.7524639610297658], "recall": [0.616, 0.792, 0.664, 0.6129032258064516, 0.6612903225806451], "f1": [0.5729902150954782, 0.781817292403279, 0.629717015691339, 0.6020546758601573, 0.6408107867891399], "time": [2.429617404937744, 2.446870803833008, 2.465532064437866, 2.4415366649627686, 2.4338579177856445]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier (TruncatedSVD)", "accuracy": [0.76, 0.808, 0.752, 0.7983870967741935, 0.8467741935483871], "precision": [0.7836915739268681, 0.8340043917435223, 0.7965418735853518, 0.80805417700579, 0.8590660770031218], "recall": [0.76, 0.808, 0.752, 0.7983870967741935, 0.8467741935483871], "f1": [0.761158139630984, 0.8024860732743889, 0.7499127969158066, 0.8012406436823047, 0.848444587539162], "time": [28.278282165527344, 28.94822597503662, 28.468808889389038, 29.088909149169922, 29.174724817276]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, stri...\n                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n                               early_stopping=False, epsilon=0.1, eta0=0.0,\n                               fit_intercept=True, l1_ratio=0.15,\n                               learning_rate='optimal', loss='hinge',\n                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n                               penalty='l2', power_t=0.5, random_state=None,\n                               shuffle=True, tol=0.001, validation_fraction=0.1,\n                               verbose=0, warm_start=False))],\n         verbose=False)", "name": "SGDClassifier", "accuracy": [0.808, 0.792, 0.776, 0.7983870967741935, 0.8870967741935484], "precision": [0.8068814044814046, 0.7968721951219512, 0.7868854515050167, 0.8182069748720603, 0.8949672244264274], "recall": [0.808, 0.792, 0.776, 0.7983870967741935, 0.8870967741935484], "f1": [0.8057950337164198, 0.7925394448688566, 0.7767449838678913, 0.7954546574712366, 0.8884239275474181], "time": [2.392808675765991, 2.378532886505127, 2.4220378398895264, 2.4214701652526855, 2.4147591590881348]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f8a8bcb6830>,\n                                 use_idf=True, vocabulary=None)),\n                ('classifier',\n                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n         verbose=False)", "name": "MultinomialNB", "accuracy": [0.552, 0.6, 0.544, 0.5645161290322581, 0.5887096774193549], "precision": [0.7869662921348315, 0.7697142857142858, 0.6756923076923077, 0.6210626185958255, 0.6235663082437276], "recall": [0.552, 0.6, 0.544, 0.5645161290322581, 0.5887096774193549], "f1": [0.5046805185920021, 0.54663642525398, 0.5003687943262412, 0.5112585932022783, 0.5395685811696826], "time": [2.356198310852051, 2.33335280418396, 2.329267740249634, 2.3986456394195557, 2.341925859451294]}
{"model": "Pipeline(memory=None,\n         steps=[('normalize', TextNormalizer(language=None)),\n                ('vectorize',\n                 TfidfVectorizer(analyzer='word', binary=False,\n                                 decode_error='strict',\n                                 dtype=<class 'numpy.float64'>,\n                                 encoding='utf-8', input='content',\n                                 lowercase=False, max_df=1.0, max_features=None,\n                                 min_df=1, ngram_range=(1, 1), norm='l2',\n                                 preprocessor=None, smooth_idf=True,\n                                 stop_words=None, strip_accents=None,\n                                 sublinear_tf=False,\n                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n                                 tokenizer=<function identity at 0x7f8a8bcb6830>,\n                                 use_idf=True, vocabulary=None)),\n                ('reduction',\n                 TruncatedSVD(algorithm='randomized', n_components=10000,\n                              n_iter=5, random_state=None, tol=0.0)),\n                ('classifier', GaussianNB(priors=None, var_smoothing=1e-09))],\n         verbose=False)", "name": "GaussianNB (TruncatedSVD)", "accuracy": [0.288, 0.384, 0.264, 0.3709677419354839, 0.3225806451612903], "precision": [0.3558010582010581, 0.46751416413373864, 0.4741538461538462, 0.42061416254964645, 0.43678512454357277], "recall": [0.288, 0.384, 0.264, 0.3709677419354839, 0.3225806451612903], "f1": [0.22307969020227086, 0.2930364661654135, 0.1483047619047619, 0.2493123635910706, 0.24529678136839075], "time": [29.031338453292847, 28.57829737663269, 28.47259497642517, 29.3249671459198, 28.185603857040405]}
